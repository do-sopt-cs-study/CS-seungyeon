클라이언트와 서버 중간에 위치하여 징검다리 역할을 해주는 서버를 Proxy Server라고 한다.
Proxy Server를 둬서 우리가 수행할 수 있는 기능은
1. Froward Proxy
2. Reverse Proxy
3. Load Balancing
이렇게 3 종류가 있다.

## 로드 밸런서란?

서버로 요청하는 클라이언트 수가 늘어나서 엑세스 수가 늘어날 때

1. scale-up : 서버의 하드웨어를 고성능으로 바꾸어 해결
    - 다수의 사용자가 집중적으로 엑세스 하면 여전히 한계 있다.
    - 비용도 너무 비싸다.

2. scale-out : 하나의 서버 성능을 올리는 게 아니라 같은 성능의 서버를 여러 대 두는 것. 분산처리
    - 요청 분배는 어떻게 할 것인가 문제 발생. 가장 대표적인 것으로는 여러 대의 웹서버를 설치하고 한 대가 담당하는 사용자의 수를 줄이는 것. 이때 부하분산 장치로서 로드밸런서 사용

<img width="500" alt="image" src="https://github.com/do-sopt-cs-study/CS-seungyeon/assets/49530253/5b534f8e-1f19-48f5-913d-01c84f53bb1f">

즉 여러 대의 서버가 분산처리할 수 있도록 요청을 나누어주는 서비스가 로드 밸런서
로드 밸런서가 요청을 분배할 때는 다음과 같은 근거를 바탕으로 분산시킵니다. 서버 부하 분산!

1. 서버의 부하 상태
    - 시험 패킷 등을 웹 서버에 보내서 응답시간을 바탕으로 판단

2. 미리 웹 서버의 능력을 설정. 그리고 비율에 따라서 분배

공통적으로 특정 웹 서버에 부하가 집중되지 않도록 함.

## 로드 밸런서 종류

- L2는 Mac 주소를 바탕으로 로드밸런싱
- L3는 IP 주소를 바탕으로 로드밸런싱
- L4는 전송계층에서 로드밸런싱. 여러 대의 서버로 로드밸런서가 요청을 나누어줌.
    - Port 정보를 바탕으로 분산이 가능하다는 장점. 만약 한 대의 서버에 포트별로 다수의 프로그램을 운영하고 있다면 최소 L4를 사용해야 한다.
- L7은 응용계층에서 로드밸런싱. 예를 들어 블로그 주소 요청을 할 때 카테고리를 두어 카테고리별로 요청을 나누어줌.
    - HTTP 헤더나 쿠키를 기준으로 트래픽 분산 가능. URL에 따라 부하를 분산시키거나 쿠키값에 따라 분산.

<img width="450" alt="image" src="https://github.com/do-sopt-cs-study/CS-seungyeon/assets/49530253/587cb89e-efe0-4100-a476-5aea8006134e">
<img width="450" alt="image" src="https://github.com/do-sopt-cs-study/CS-seungyeon/assets/49530253/48346b61-77ff-4ed9-b905-537b8015588c">

<img width="700" alt="image" src="https://github.com/do-sopt-cs-study/CS-seungyeon/assets/49530253/1f916397-c141-4222-b114-e09d38a2b8ea">


## 로드밸런싱 알고리즘

- 라운드로빈 방식
    - 서버에 들어온 요청을 순서대로 돌아가면서 서버에 배정.
    - 모든 서버가 동일한 스펙을 가지고 있을 때 유리.
    - 세션이 오래 지속되지 않는 경우 유리.

- 가중 라운드로빈 방식
    - 서버마다 가중치를 매기고 가중치에 따라서 클라이언트 요청을 배분.
    - 서버의 트래픽 처리 능력이 다를 때 유리.

- IP 해시 방식
    - 클라이언트 IP 주소를 활용해서 특정 서버로 매칭.
    - 동일한 클라이언트의 요청은 동일한 서버로 연결됨.

- 최소 연결 방식
    - 요청 들어온 시점에 가장 연결 상태가 적은 서버에 트래픽을 배분.
    - 세션이 길어지거나 서버에 분배된 트래픽들이 일정하지 않을 때 적합.

- 최소 리스폰타임
    - 서버의 현재 연결 상태와 응답시간을 고려하여 트래픽 배분.
    - 가장 적은 연결상태와 응답시간을 보인 서버에 우선적으로 트래픽 배분.


## Proxy

프록시란, 웹 서버에서 중개자 역할, 무언가의 대리 역할을 한다.
클라이언트와 서버 사이에 위치해서 그들간의 http 메시지를 정리한다. 중간에서 통신을 대신 수행
클라이언트와 서버의 대리 역할을 한다.

- Forward Proxy
    - 클라이언트 대신 서버에 요청을 보내주는 역할
    - Proxy가 내 컴퓨터 가까이 있다. 클라이언트와 인터넷 사이에 프록시가 위치함.
    - 클라이언트의 대리인
        - 로컬 네트워크와 인터넷 사이에 트래픽 제어 가능.
        - 캐싱 기능. 서버까지 거치지 않고 바로 프록시에서 캐싱된 정보를 이용해 응답할 수 있다. 인기있는 요청 관리하고, 해당 요청이 왔을 때 서버까지 가지 않고 프록시에서 응답하게 함. 느리고 비싼 커뮤니케이션 비용을 줄일 수 있다.
        - 클라이언트 익명성 유지 가능. 프록시를 통해 익명화되어 공통 식별 정보 헤더를 포함하지 않는다. Http 메시지에서 신원 정보들을 제거해서 개인정보보호나 익명성 보장 가능. 클라이언트 요청을 Proxy 요청인 듯 위장하고 클라이언트에게 응답을 보낼 때도 서버가 보낸 척 위장 가능.
        - 필터링 가능(서버에서 내려준 응답을 클라이언트로 보낼 때 필터링).
        - 접근제한(클라이언트에서 서버로 요청 갈 때 아예 서버로의 접근을 차단).

- Reverse Proxy
    - 서버 대신 클라이언트에 응답을 보내주는, 서버의 응답을 대신 클라이언트에 전달해주는 역할
    - Proxy가 서버 가까이 있다. 네트워크 가장 끝단에 있는 웹 서버의 바로 앞에 위치함.
    - 서버 개발자가 설정을 해준다. 서버를 대신하여 클라이언트 요청을 받는다.
        - 웹 서버로 향하는 모든 요청 처리 가능.
        - 보안 높아짐. 클라이언트의 IP와 Port가 외부로 드러나지 않음.
        - SSL 중앙화 관리. 서버를 여러 대 뒀을 때, 서버마다 SSL 인증서를 관리한다면 번거롭다. 프록시 서버가 SSL 인증서를 모아서 관리하면 Client-Reverse Proxy Server는 HTTPS로 통신하고 Proxy-Server는 HTTP로 통신 가능
        - 성능개선 강화 가능.
        - 캐싱 가능.
        - 로드 밸런싱. 로드밸런서를 따로 둬서 로드 밸런싱을 할 수도 있지만 Reverse Proxy도 이 장점을 충분히 가져갈 수 있다. 서버가 요청을 나누어가질 때 프록시가 이를 분산한다.

프록시는 네트워크 어디든 배치 가능하다.

<img width="500" alt="image" src="https://github.com/do-sopt-cs-study/CS-seungyeon/assets/49530253/a5f3eca7-2273-45c6-894e-79054ff2bec6">


















